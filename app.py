from flask import Flask, request
from google.cloud import bigquery, storage
import os
import traceback
import logging

app = Flask(__name__)

# Configure logging
logging.basicConfig(level=logging.INFO)

# Initialize BigQuery and Storage clients
bigquery_client = bigquery.Client()
storage_client = storage.Client()

# Define dataset, table, and bucket
DATASET_ID = "transactions_dataset"
TABLE_ID = "transactions_partitioned"
BUCKET_NAME = "retailfrauddetectionai-event-driven-bucket"

@app.route("/", methods=["POST"])
def handle_pubsub():
    try:
        logging.info("üìå D√©but du traitement du fichier CSV...")

        # 1. Lister les fichiers disponibles dans le bucket
        logging.info("üìå Liste des fichiers dans le bucket...")
        blobs = storage_client.list_blobs(BUCKET_NAME)
        csv_file = next((blob.name for blob in blobs if blob.name.endswith(".csv")), None)

        if not csv_file:
            logging.error("‚ùå Aucun fichier CSV trouv√© dans le bucket.")
            return "Aucun fichier CSV trouv√© dans le bucket.", 404

        logging.info(f"‚úÖ Fichier CSV trouv√© : {csv_file}")

        # 2. T√©l√©charger le fichier CSV
        input_file_path = "/tmp/input.csv"
        logging.info(f"üìå T√©l√©chargement du fichier {csv_file} depuis le bucket...")
        blob = storage_client.bucket(BUCKET_NAME).blob(csv_file)
        blob.download_to_filename(input_file_path)

        logging.info(f"‚úÖ Fichier t√©l√©charg√© avec succ√®s : {input_file_path}")

        # 3. Configurer le job de chargement BigQuery sans sch√©ma explicite
        logging.info("üìå Configuration du job de chargement BigQuery...")
        job_config = bigquery.LoadJobConfig(
            source_format=bigquery.SourceFormat.CSV,
            skip_leading_rows=1,  # Ignorer la ligne d'en-t√™te
            autodetect=True,  # Laisser BigQuery d√©tecter le sch√©ma
            write_disposition=bigquery.WriteDisposition.WRITE_APPEND  # Ajouter √† la table existante
        )

        # 4. Charger les donn√©es dans BigQuery
        logging.info("‚ö°Ô∏è Tentative de chargement des donn√©es dans BigQuery...")
        try:
            with open(input_file_path, "rb") as source_file:
                load_job = bigquery_client.load_table_from_file(
                    source_file,
                    f"{DATASET_ID}.{TABLE_ID}",
                    job_config=job_config
                )

            # Attendre la fin du job
            logging.info("üìå Attente de la fin du job BigQuery...")
            load_job.result()

            logging.info(f"‚úÖ Donn√©es charg√©es avec succ√®s dans {DATASET_ID}.{TABLE_ID}")
            return f"Fichier charg√© avec succ√®s dans {DATASET_ID}.{TABLE_ID}.", 200

        except Exception as bq_error:
            logging.error(f"‚ùå Erreur lors du chargement dans BigQuery : {str(bq_error)}")
            traceback.print_exc()
            return f"Erreur BigQuery : {str(bq_error)}", 500

    except Exception as e:
        logging.error(f"‚ùå Erreur g√©n√©rale dans le script : {str(e)}")
        traceback.print_exc()
        return f"Erreur interne : {str(e)}", 500


if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    logging.info(f"üöÄ Lancement de l'application sur le port {port}...")
    app.run(host="0.0.0.0", port=port)